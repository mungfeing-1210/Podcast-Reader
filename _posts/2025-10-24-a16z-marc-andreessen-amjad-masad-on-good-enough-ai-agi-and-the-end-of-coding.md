---
layout: post
title: "A16Z · Marc Andreessen & Amjad Masad on “Good Enough” AI, AGI, and the End of Coding"
date: 2025-10-24
tags: [AI, 转写]
---

# 播客: AI与Replit，编程的自然语言未来

当前，我们正身处一场技术革命之中，AI所展现出的能力在五年前乃至十年前被认为是不可思议的“魔法”。这项技术以惊人的速度发展，然而，我们却常感到失望，认为其进步不够迅速，甚至隐约担忧它可能即将停滞。这使得我们同时处于一种极度兴奋与近乎绝望的矛盾情绪之中。尽管AI的速度已远超以往，但仍未达到我们期望的计算机处理速度，更像是在观察一位被兴奋剂激发的世界顶级程序员在工作。

## Replit AI：编程新手体验

假设一位编程新手，例如一名学生，或仅有一些初步的编码经验（如Excel宏），但并非专业的编程大师。当他们首次接触Replit及其AI功能时，将体验到怎样的流程？

Replit致力于消除传统开发环境设置的繁琐，让用户直接专注于核心创意。
- **直观的起点**: 无论用户是否有编码经验，Replit的首要目标是移除设置开发环境等障碍，让用户能直接投入到构建自己的想法中。
- **表达意图**: 用户只需在提示框中用日常英语描述想实现的目标，无论是“我想构建一个产品”、“解决一个问题”还是“进行数据可视化”。例如，用户可以输入“我想在线销售可丽饼”，即使是这样简单的四五个词，系统也能理解。
- **智能技术栈选择**: 系统不要求用户指定编程语言或技术栈，它会根据用户需求智能分类并推荐最佳方案。若为数据应用，可能选择Python；若为Web应用，则选用JavaScript和PostgreSQL等。当然，用户也可明确指定使用自己熟悉的语言，如Python。Replit作为拥有近十年历史的平台，支持所有主流编程语言。
- **多语言支持**: Replit的AI不仅支持英语，目前也支持其他主流世界语言，如日语，并拥有大量日本用户。

## 编程语言的演进与抽象化

回顾编程历史，曾进行过一番研究，以理解我们所处的这个特殊时刻。格蕾丝·霍珀（Grace Hopper），编译器的发明者，曾指出在机器码编程盛行的时代，专家总是需要掌握底层机器原理。但她的愿景是实现一个能够用英语编程的世界。她认为C语言就是这一愿景的开端。

然而，这仅仅是开始。从C语言到更高级的Python和JavaScript，编程的抽象层次不断提高。我们现在正迈向新的里程碑：
- **从语法到思想**: 这一刻，我们不再需要输入具体的编程语法，而是直接输入我们的想法，由机器来编写代码。这正是我们最终追求的目标。
- **消除偶然复杂性**: 弗雷德·布鲁克斯（Fred Brooks）曾区分编程的“本质复杂性”（如如何将初创公司推向市场，如何建立业务）与“偶然复杂性”（如使用哪个包管理器）。Replit多年来一直致力于抽象化这些偶然复杂性，如今，代码本身也成为了瓶颈。代码语法对于普通人而言仍不自然，因此，最终的目标是让英语成为编程语言。

## 编程社群对抽象化的反应

历史上，每次编程抽象层次的提升，总会伴随着一部分“老派”程序员的抵触：
- **机器码与汇编**: 曾经，编写汇编语言的程序员会受到编写机器码（0和1）的“真正程序员”的轻视，认为汇编已经过于高级。
- **汇编与高级语言**: 随后，汇编程序员又会鄙视使用Basic或C语言的开发者。
- **JavaScript框架**: 我本人在Facebook参与了现代JavaScript栈（如ReactJS）的构建，当时也遭到了坚持使用原生JavaScript的程序员的批评。

这种现象周而复始。那些在前一波技术浪潮中建立职业生涯的程序员，往往会对新的抽象化浪潮产生抵触。然而，每一次高级抽象的引入，都意味着编程的**民主化**，降低了入门门槛。

## Replit AI的后续工作流程

当用户输入英文需求后，Replit的代理（Agent）会执行一系列操作：
1. **理解与确认**: 首先，代理会展示它对用户需求的理解，以确保双方达成共识。尽管用户界面仍有改进空间，但目前它会列出一系列将要执行的任务。
2. **任务规划**: 代理会根据需求自动规划任务，例如：
    - 设置数据库来存储数据。
    - 集成Shopify或Stripe以处理支付。
3. **开发模式选择**: 代理会提供两个初始选项：
    - **从设计开始**: 优先进行设计迭代，与用户反复沟通以确定最终设计。
    - **构建完整应用**: 如果选择此项，代理将花费20-40分钟自动完成大部分开发工作。
4. **自动化构建与测试**: 代理的“Agent 3”版本引入了创新功能：
    - **自动部署**: 它会设置数据库、执行数据迁移、编写SQL，并构建网站。
    - **集成测试**: 完成代码编写后，代理会启动浏览器进行测试，并针对发现的问题自动迭代修复代码。

这意味着用户只需等待通知，一个完整的应用程序就能在短时间内自动构建完成。



系统 Agent 会花费 20 到 30 分钟构建应用程序，并向用户发送通知，告知应用已准备就绪。用户可以在手机上测试应用。如果发现 Bug 或问题，用户可以返回电脑，向 Agent 描述问题，指出应用未达到预期效果。如果应用符合预期，用户只需点击几下即可发布。值得一提的是，许多用户的想法在 20 到 30 分钟内就能转化为实际可用的应用，这效率令人惊叹。

### 自动化部署与 Replit 的透明性

在发布环节，系统会在云端配置虚拟机并部署数据库。所有部署工作都已完成，用户即刻拥有了一个生产数据库。

回顾两三年前，要达到这一步需要经历一系列繁琐的步骤：设置本地开发环境、注册 AWS 账户、配置数据库和虚拟机、以及创建整个部署流水线。如今，这一切都已自动化。即使是普通用户甚至孩子也能轻松完成。

对于专业程序员而言，Replit 的独特之处在于其作为集成开发环境（IDE）的深厚背景。如果程序员对 Agent 的具体操作感到好奇，他们可以“剥离层级”，打开文件树查看文件，使用 Git 推送到 GitHub，甚至连接到自己偏好的编辑器，如 Emacs。Replit 作为一个抽象了所有复杂性的平台，同时保留了所有底层细节，供用户随时深入探究。

### Agent：新的编程主体

在这种新的范式下，真正的“用户”已不再是人类，而是“Agent 程序员”。Agent 会列出它将要执行的一系列任务，然后由它实际执行这些任务。

一个有趣的现象是，当 Replit 推出 Agent 后，原本旨在为亚洲用户提供更快响应速度的亚洲服务器，其用户体验反而显著变差。这是因为 AI Agent 位于美国，用户请求首先发送给美国的 Agent，然后 Agent 再与全球其他地区的机器进行交互。这清楚地表明，Agent 已经成为了实际的编程执行者。

Agent 是一个软件程序，它像人类用户一样，能够使用 Replit 平台的各项功能。它拥有访问各种工具的权限，包括：
*   编写、编辑、删除文件
*   搜索包索引、安装软件包
*   配置数据库、配置对象存储
它是一个具备工具和接口的程序员，其交互方式与人类程序员高度相似。

### AI Agent 的自主运行与长周期推理

AI 行业内部一直存在关于 Agent 自主性的讨论：Agent 能够在多长时间内独立运行并完成任务？早期的 Agent 通常只能运行两三分钟，随后便会开始混淆、偏离主线，甚至“失控”。但近年来，Agent 的运行时间显著延长，能够执行更复杂的任务。

我们关注的核心指标是 Agent 的“一致性”——即它能在多长时间内保持逻辑连贯、掌控全局，而不至于崩溃。早在 2023 年甚至更早，软件 Agent 的概念就已出现，但一致性问题一直是其主要障碍。Agent 运行一两分钟后便会积累错误，导致无法恢复。有时，它们会变得越来越困惑，甚至开始说中文，做出奇怪的举动。

然而，大约在去年，我们看到 Agent 的运行时间突破了 3 到 5 分钟的界限，这让我们觉得“长周期推理”问题正在得到解决。

“长周期推理”指的是 Agent 在长时间内以复杂方式处理事实和逻辑，并且能够进行包含多个步骤的推理过程。

### 长周期推理的技术突破

大型语言模型（LLM）的工作原理基于“上下文”（context），这相当于它们的记忆。上下文包含用户输入、环境输入，以及 AI 在推理过程中所有的内部思考。例如，当 AI 进行推理时，它会自言自语：“现在我需要设置一个数据库。我有什么工具？有一个 PostgreSQL 工具，我试试用它。我得到了反馈，现在查看反馈内容。”

这个上下文框，即内存空间，承载着用户输入、环境输入和机器的内部思维。长期以来，在这个上下文上进行推理一直是挑战，导致 AI 很容易偏离轨道。现在，Agent 能够始终保持一致性地完成整个思考过程。

除了基础模型本身的进步，还有许多围绕“上下文压缩”的创新。尽管 LLM 被宣传为支持百万级别的 Token 长度（相当于一百万个单词），但实际上在约 20 万 Token 后就会出现困难。因此，系统会执行大量内存压缩操作，例如，将多段日志总结为一条语句，或者将复杂的数据库设置简化为简明描述。通过定期压缩上下文，我们可以确保 Agent 保持逻辑一致性。

那么，基础模型中促成这种长周期推理的关键技术突破是什么？

我认为是**强化学习（Reinforcement Learning, RL）**。预训练模型的训练方式是阅读文本，然后遮盖掉最后的词语并尝试猜测，这使得它们能够有效地学习语言。然而，这种训练模式本身并不直接包含长周期推理的能力。要超越这一限制，需要一种在长上下文中解决问题的能力。

特别是结合代码执行的强化学习，赋予了 LLM 展开“轨迹”（trajectories）的能力。在 AI 领域，“轨迹”是指为达到解决方案而进行的一系列逐步推理链。我的理解是，强化学习的运作方式是将 LLM 放置在一个编程环境（如 Replit）中，给它一个代码库及其中的 Bug，并要求它解决问题。人类训练者预先知道解决方案（例如，通过 GitHub 上的 Pull Request 或可验证的单元测试）。

LLM 会展开许多不同的轨迹来尝试解决问题。其中一些轨迹可能会成功解决 Bug，达到解决方案，而许多其他轨迹则可能偏离轨道。系统会奖励那些成功解决问题的轨迹，从而训练模型了解如何解决这类问题。这正是我们能够扩展推理链的关键。



## 模型的长链推理能力

在长链推理方面，模型当前的表现如何，以及我们如何衡量其进步？一家名为 Meter 的非营利组织通过建立基准来评估模型在保持连贯性、执行有用任务（包括编程）时的运行时间。他们去年底发布的一份报告指出，模型能够保持推理连贯性的时长每七个月翻一番。然而，我们认为这个速度被严重低估了。

### Applay 的实践与成果

在 Agent3，我们密切关注模型在真实用户任务中的表现，而非仅仅依靠基准测试。我们通过 A/B 测试来衡量用户是否成功完成任务。对我们而言，成功的终极标志是用户是否发布了应用，因为这代表着他们愿意为应用付费，体现了其经济价值。

从我们的数据来看，Agent1 运行时长约为 2 分钟，随后可能开始出现问题。Agent2 于今年 2 月发布，运行时长可达 20 分钟。而 Agent3 则能达到 200 分钟。尽管有些用户能将其推至 12 小时甚至更长，但我们对其在极端时长下的表现尚不完全自信。不过，在 2 到 3 小时的运行时间内，Agent3 的表现已经达到了令人难以置信的水平。

## 核心创新：验证循环机制

除了模型本身的进步，使推理链得以大幅延长的主要创新在于引入了**验证循环**。我曾读过 Nvidia 的一篇研究论文，他们尝试使用 DeepSeek 编写 GPU 内核。大约七个月前 DeepSeek 刚推出时，Nvidia 发现，如果在循环中加入一个验证器，DeepSeek 就能运行约 20 分钟，并生成经过优化的内核。

这给我们带来了启发。作为一家专注于智能体实验室或应用开发的公司，我们不负责基础模型的研究，但在此之上进行了大量开发。我们认识到，要将智能体的运行时间从 10-20 分钟（即大型语言模型保持连贯性的时间）提升到 200-300 分钟，验证循环是不可或缺的。因此，我们投入了大量精力构建脚手架，让智能体能够启动浏览器并进行模拟用户操作的测试。

### Applay 的多智能体验证系统

当验证器被引入系统后，事情的运作方式如下：一个智能体运行约 20 分钟，然后系统会启动另一个智能体，它会打开浏览器并测试前一个智能体的工作成果。这是一个**多智能体系统**。如果发现了 Bug，它会开启一条新的执行路径：首先总结前 20 分钟的工作内容，然后将这个总结和发现的 Bug 作为新的提示，提供给下一个智能体。通过这种方式，我们可以不断地将前一个步骤压缩成一个段落，作为下一个智能体的提示，从而实现几乎**无限长的推理链**，就像一场接力赛。这本质上是智能体在提示下一个智能体。

## 智能体的工作流程与效率

那么，当一个现代智能体运行 200 分钟时，它的运行速度如何？它是否像人类一样思考和处理任务？

可以说，智能体的运行速度比人类快，但并非达到我们期望的“计算机速度”。更像是**一位世界顶尖程序员在兴奋剂作用下的工作状态**。你可以看到文件差异（file diffs）飞速生成，但它也会时不时停下来“思考”，回顾：“我做了这些，我走在正确的轨道上吗？”它会进行自我反思，审查工作，决定下一步，或者将任务转交给测试智能体。

例如，当遇到问题时，它会调用工具。如果发现 PostgreSQL 15 与某个数据库 ORM 包不兼容，它会说：“这是一个我从未见过的问题，我要去网上搜索。”然后它会调用网络搜索工具来解决。整个过程看起来就像一个人类程序员在工作，这令人着迷。观察工具链、推理链和测试链的运行，就像在看一个高效的程序员在工作。

## 从“随机鹦鹉”到通用推理

我们正在接近 AI 的“圣杯”，即机器的**通用推理能力**。谈到验证循环，对于播客听众中不了解技术细节的朋友，我试着描述一下我的理解是否正确。

像 ChatGPT 这样的大型语言模型，大约两年前刚推出时，它在语言的流畅性方面令人惊叹，无论是写莎士比亚十四行诗还是说唱歌词，都非常出色。它在人类对话方面表现惊人，但如果让它解决涉及理性思考或问题解决的问题，比如数学，它就会立刻暴露出弱点。最初，即使是非常基本的数学问题，它也无法解决。

### 早期大型语言模型的局限

即使后来它在解决这些问题上有所改进，但如果让它处理更复杂的计算，比如两个大数相加或相乘，它仍然会遇到困难。还有一个著名的“草莓测试”，即数单词“strawberry”中有多少个“r”。在很长一段时间里，它总是错误地回答只有两个“r”，而正确答案是三个。因此，当时人们甚至创造了一个带有贬义的词——**“随机鹦鹉”（stochastic parrot）**来形容它。

“随机鹦鹉”这个词意味着模型像一个随机的鹦鹉，只是重复它认为你想听到的东西，但并不真正理解。在纯粹的预训练大型语言模型世界中，这在某种程度上是事实。

### AlphaGo 带来的范式转变

然而，正如你所说，过去一年左右，**强化学习**和**验证循环**被引入进来，这并非全新的理念，它与 **AlphaGo** 的突破息息相关。

AlphaGo 的突破发生在 2015-2016 年，它融合了人工智能领域两大流派：**连接主义**（认为神经网络是实现 AI 的真正途径）和**符号系统**（认为离散推理、事实和知识库才是正确方向）。AlphaGo 的工作原理是，它有一个神经网络来生成潜在的围棋走法，然后在此之上应用蒙特卡洛树搜索算法。这个更离散的算法会对这些走法进行排序，并通过验证来找到最佳走法，这是一种更经典的算法方法。

这标志着一场运动的复兴：我们将强大的生成式神经网络（即 LLM）与更离散的验证方法相结合，以判断其行为是否正确，并将此纳入训练循环。一旦这样做，大型语言模型就会开始获得新的能力，例如进行数学和代码推理等。

是的，这正是关键。为了让强化学习发挥作用，让大型语言模型能够进行推理，其核心在于**问题描述必须具有明确和可验证的答案**。



### 可验证答案的重要性与AI进展分野

大型语言模型（LMS）有效推理的关键在于问题陈述必须具有明确且可验证的答案。这意味着其输出能够被清晰地判定为正确或错误。

### 不同领域的验证难度

我们来看一些例子：

*   **医学诊断：** 如果一个诊断能被一组人类医生共同认可，或者能够实际治愈病症，那么它是可验证的。
*   **法律论证：** 一个能在陪审团面前成功辩护并导致无罪判决的论证是可验证的。
*   **数学：** 一个能被正确解答的方程式。
*   **物理学：** 一个在现实世界中能够实际运作的结果。
*   **土木工程：** 一座不会倒塌的桥梁。

然而，像法律和医疗健康这样的领域，其验证标准目前仍显得“模糊”或“软性”，不像数学、物理或编程那样“硬性”。在数学领域，可以使用像Lean这样的形式化证明语言来运行验证；在编程中，可以运行计算机代码；在物理或土木工程中，可以进行模拟。但我们无法“运行一个诊断”。虽然诊断可以由人类专家进行验证，但这更像是通过人类反馈进行强化学习（RLHF），而非完全自主和可扩展的训练。

### 编程领域进展加速的原因

编程领域之所以进展最快，正是因为它允许快速生成问题并即时验证。在编程中，存在两种核心测试：

1.  代码是否能够编译？
2.  代码是否能产生正确的输出？

仅仅编译成功并不意味着输出正确，而验证正确输出的难度更大。

**Swebench基准测试**
Swebench是一个科学家团队建立的基准测试，用于评估AI在软件工程任务上的能力。它包含了一系列经过验证的、带有明确错误描述和相应解决方案（包括单元测试）的GitHub Pull Request。AI在该基准上的表现正在迅速提升：去年（2024年初）可能只有约5%的完成率，而现在，使用Claude 4.5等先进模型，已达到约82%的水平。这表明AI在软件工程任务上取得了显著的进步。

虽然Swebench的数据主要来源于GitHub上的现有语料库，并且可以生成合成数据，但这并非无限可扩展。因为合成数据的生成仍需部分人类验证，尽管基础模型正在探索更自主的合成训练数据生成方式。

### 训练数据生成的新模式

目前，基础模型公司正在采取两种主要策略来获取高质量训练数据：

1.  **雇佣人类专家：** 他们雇佣数学家、物理学家和程序员等人类专家，来创建具有已知正确结果的代码，从而为强化学习循环提供精确的训练。
2.  **构建自主系统：** 开发能够自动生成训练数据、测试用例和验证结果的软件系统，即所谓的“合成训练数据”生成。

### 领域发展速度差异与 AGI 的挑战

这些先进的训练和验证方法在“硬性”领域（如编程、数学和物理）表现出色，但在“软性”领域（如医疗保健、创意写作）的进展则相对缓慢。所谓“软性”领域，是指那些难以甚至不可能以确定性、事实性和无争议的方式验证结果正确性的领域，例如许多慢性病诊断，它们通常涉及复杂的症状集群而非简单的对错判断。

因此，AI进展的关键变量在于问题本身的**具体性**——即是否能够得到一个真假分明的、可验证的答案，而非问题的内在难度。只要一个领域存在可验证的答案，我们就能预期其AI应用将实现极其迅速的进步。这包括数学、物理、化学、大部分编程领域、生物（如蛋白质组学）以及某些机器人技术领域（结果明确）。

**编程的未来展望**
我们预计编程领域的进展将是爆发性的。未来一年内，开发者可能不再是独立操作，而是同时启动多个（如5-10个）AI代理，并行处理任务，例如规划新功能、重构数据库，并自动合并代码。结合多模态界面（如图形和图表）进行设计和创意互动，软件开发将成为一个激动人心的领域。届时，普通人可能都能达到如今Google高级软件工程师的水平。

然而，在医疗健康或更具创造性的领域，我们尚未看到如此迅速的提升。这引出了一个奇特的现象：一方面，我们对AI技术惊叹不已，它正以惊人的速度发展；另一方面，我们又感到失望，认为它发展得不够快，甚至可能停滞不前。我们一方面应该对这些在五年前甚至十年前看来不可思议的“魔法”感到兴奋，另一方面也需要认识到实际的局限性，不能将所有进展无限外推。

当前，整个美国经济似乎都在押注通用人工智能（AGI）。但一个关键问题是：我们真的在通往AGI的道路上吗？有些迹象表明并非如此，因为在不同领域之间，缺乏显著的迁移学习。例如，编程能力的极大提升，并未直接带来其他领域的同等进步。



## 领域专精与通用推理的挑战

人工智能跨领域学习的效率仍面临挑战。例如，若我们在代码方面取得显著进步，这并不意味着我们的通用推理能力会随之提高。生物、化学、物理、数学或法律等特定领域，依然需要独立的训练数据和强化学习（RL）环境来提升性能。

## “苦涩的教训”与数据稀缺的争议

### Richard Sutton对“苦涩的教训”的反思
近期，在Richard Sutton的访谈之后，人工智能界就此展开了热烈讨论。Sutton在其文章《苦涩的教训》中提出，AI研究存在无限可扩展的方法：通过投入更多的计算资源和数据，可以不断提升AI性能，最终实现通用人工智能（AGI）。然而，在访谈中，Sutton似乎对其先前提出的“苦涩的教训”路径产生了怀疑，认为当前严重依赖人类数据和标注的训练模式，可能并未真正遵循这一路径，甚至可能背道而驰。

### Iliya Sutskever的“化石燃料”论点
OpenAI的Iliya Sutskever也提出了一个引人深思的观点，将其比作“化石燃料”问题：我们正在面临训练数据枯竭的困境。互联网上绝大多数可用数据已经被模型吸收。虽然仍有一些“私有数据池”等待挖掘，但与直接从互联网获取数据相比，生成新的高质量数据既困难又昂贵。

## 泛化能力：人类与机器的对比

### 迁移学习的定义与人类局限
**迁移学习**是指机器在一个领域成为专家后，能够将知识泛化到其他领域的能力。然而，审视人类自身，会发现真正擅长迁移学习的人并不多。恰恰相反，一个人在一个领域越是专精，在其他领域就越可能存在认知盲区。

### 公众人物跨领域局限的案例
*   **经济学家Paul Krugman**：他是一位杰出的经济学家，但他曾将互联网的重要性与传真机相提并论，这暴露了他对计算机运作原理的缺乏理解。
*   **物理学家爱因斯坦**：作为一位卓越的物理学家，爱因斯坦在政治方面的见解（例如他对斯大林主义的看法）却显得“不着边际”。他的物理学知识未能有效地迁移到政治分析中，其政治评论听起来像是一名本科生的狂热言论。

## AGI定义的困境与“人工智能效应”

### 对AGI目标的反思
这引发了一个问题：我们是否已经达到“人类水平的AGI”？如果人类自身在迁移学习方面表现平平，那么AGI的定义或许应该超越人类水平，或者说是指能够完全实现跨领域知识泛化的能力，这可能是一种我们从未见过的现象。我们可能设定了一个理想化的目标，它远超人类所能达到的范畴，以至于与人类的比较不再具有相关性。AGI通常被定义为“能够在所有方面都比人类做得更好”，但如果人类根本不擅长迁移学习，那么人工智能即便只展现出微小的迁移学习能力，也可能具有重大意义，或者说，因为它超越了人类，这种比较本身就无关紧要。

### “人工智能效应”：移动的目标
在AI领域，存在一个著名的现象，即“人工智能效应”（或称**“移动的目标”**）：人工智能的定义总是被设定为机器目前尚未能完成的“下一个”任务。
*   **国际象棋为例**：长期以来，AI能否在国际象棋中击败人类被视为AI的重要标志。然而，一旦机器实现了这一目标，它就不再被称为“AI”，而变成了“计算机象棋”，被认为“无聊”，最终只是手机上的一个应用程序。
*   **图灵测试为例**：图灵测试曾是衡量AI智能的重要标准，甚至有电影以此为主题。然而，当机器真正通过图灵测试时，却几乎没有引起任何庆祝或关注，仿佛人们对此毫无察觉，认为这根本不值得称道。

AI科学家们常常抱怨，他们总是被以尚未解决的“下一个”问题来评判，而非已经取得的成就。然而，他们自己也可能为AI设定了一个“不合理”的终极目标，即在所有方面都超越人类，这导致了一种在发展过程中不断“自我鞭笞”的状态。

## 功能性AGI与GPT-5的“回报递减”

### 功能性AGI的愿景
我开始思考“功能性AGI”这个概念。在我看来，真正的AGI定义是：一个AI系统，无论置身于何种环境，都能高效地学习，几乎不需要先验知识，并且能将所学知识跨领域迁移。然而，也许我们能通过另一种方式实现**功能性AGI**：即收集世界上所有有价值的经济活动数据，并在此基础上训练一个大型语言模型（LLM）或相同的基础模型，然后将其应用于经济的各个部门，从而自动化大部分劳动力。我认为我们正朝着这个方向稳步前进。

### GPT-5的体验与预期落差
GPT-5发布后，我曾在推特上表示感受到了“回报递减”。我原以为它会在“人类化”方面有显著提升，但实际体验是，GPT-5在“可验证的领域”表现更好，但在其他方面，特别是“人类角度”上，并没有感觉明显进步，甚至有所退步。Reddit上甚至出现了一股反对OpenAI和Sam Altman的声浪，因为许多用户觉得他们“失去了一个朋友”——相比之下，GPT-4感觉更具人情味、更亲近，而GPT-5则显得更为机械、理性，专注于思考一切。

我曾期待，从GPT-2到GPT-3的飞跃，清晰地展现了AI变得更加人性化，更贴近我们的经验，仿佛它能更好地理解世界。然而，从GPT-3到GPT-4再到GPT-5，并没有感受到这种整体“存在感”的显著提升。这引出了一个问题：这种期待是基于情感维度吗？还是基于对复杂、争议性话题（例如世贸中心7号楼事件）的深入推理能力？



### AI处理争议问题与AGI的定义

当前人工智能在处理具有争议性的话题上仍面临挑战。例如，关于“世贸中心7号楼发生了什么”或“新冠病毒的起源”这类问题，AI目前无法像解决编程难题那样进行深入的批判性思考和推理，尚未展现出显著进展。

另一位嘉宾分享了他使用AI的不同方式和期望。他主要将AI视为一位随时待命的“博士生”，要求它解释各种概念，而非进行对话。

#### AI的知识合成能力

尤其值得一提的是，结合GPT-5 Pro及“深度推理”或“Rock 4 Heavy”等高端模型，AI能够按需生成长达30至40页的专题报告。例如，当被问及“先进经济体对原材料或制成品征收关税，最终由谁来承担？”这一复杂的经济学问题时，AI能够提供出色的分析。它通过从网络收集信息并进行综合，生成一份连贯、高质量的PDF报告。据观察，这些报告在逻辑上严密，内容翔实，其专业水准堪比聘请斯坦福大学的优秀经济学博士后所做的研究。

然而，这种能力主要在于**合成现有知识**，而非创造全新知识。这引发了一个哲学问题：人类所创造的“新知识”究竟有多少是真正的原创，又有多少是在前人成果基础上进行的高级综合？许多书籍的撰写本身就是一种综合过程，但也被视为创造性的成就。

#### AI与争议性信息

面对当前信息生态的混乱，人们渴望AI能够帮助从第一性原理出发进行推理，以获取真实可靠的信息。嘉宾尝试让AI扮演“辩论中的强硬角色”，例如，分别“钢化”关于新冠病毒是实验室泄漏和自然起源的两种观点。结果显示，AI能够生成篇幅长达30页的、极具说服力的论证。

过去，由于强化学习与人类反馈（RLHF）的限制，AI在面对真正有争议的话题时会表现出抵触，甚至可能“训斥”提问者是阴谋论者。但随着技术发展，一些大型模型现在对探讨这类话题持更加开放的态度。

#### AGI的定义与未来展望

关于通用人工智能（AGI）的定义，目前存在多种观点。传统的AGI定义常将AI与人类表现进行比较。这类似于自动驾驶汽车的争论：一辆自动驾驶汽车是“完美”的驾驶员，还是“比人类更好”的驾驶员？超越“完美驾驶员”的境界，或许是能够“知晓目的地”的汽车。

对于AI的未来，存在两种主要看法：
1.  **实用主义者**：从企业家角度看，当前的AI工具已提供了大量可供开发的应用。即使AI技术在未来五年内不再有根本性突破，仅凭现有基础模型和基础设施层，仍有巨大的应用和创新空间。
2.  **学术探究者**：从小对意识和智能的本质感兴趣，他更倾向于理查德·萨顿（Richard Sutton）和深度思维（DeepMind）联合创始人沙恩·莱格（Shane Legg）等人提出的AGI定义，即**高效持续学习**。

这种高效持续学习的AGI意味着，它能被置于任何领域，无需大量预先知识，便能在短时间内（如人类学习驾驶所需数月）掌握该领域的技能、理解和推理能力。这种普遍化的技能习得和理解能力将是真正改变世界的突破，它将加深我们对人类心智和意识的理解，并将人类文明推向一个新的高度。然而，对于这种AGI突破的可能性，嘉宾目前持谨慎（看跌）态度，因为现有AI的实用性已经非常高。



## AGI 突破的“局部最优陷阱”

对于实现真正的通用人工智能（AGI）突破，我持悲观态度。原因在于，我们目前所构建的工具已经足够实用，并具有巨大的经济价值。从某种意义上说，“足够好便是敌人”。你可能还记得那篇关于“Worse is better”的文章。我们现在正处于一个“局部最优陷阱”中，因为现有系统在经济生产性工作方面表现足够好，这减轻了系统追求通用解决方案的压力。

诚然，像 Rich Sutton 这样少数坚持不懈的研究者仍在尝试沿着那条路径前进，也许他们会成功。然而，巨大的优化能量正集中于我们目前所深陷的局部最优。讽刺的是，每个人都在担忧投入数万亿美元构建这些东西，但最令人啼笑皆非的结局是，这些巨额资金最终可能只是投入了一个局部最优，而非解决通用问题。当然，通用问题本身可能在我们的有生之年都无法解决，谁知道呢？

### 大型语言模型与新研究方向

那么，你认为我们已经榨干了大型语言模型的潜力，或者说还有其他让你特别兴奋的研究方向吗？

问题在于，我认为真正突破性的新方向并不多。强化学习（RL）领域的突破令人非常兴奋，但我们对此的认识也已有十年之久，即如何将生成式系统与树搜索等技术结合。这个领域仍有很大发展空间。我猜测，强化学习的最初奠基者们正试图沿着这条路，从零开始引导智能。例如，Carmack 就在走这条路，而非大型语言模型路径。尽管有这些努力，我目前尚未看到太多实际进展或成果，尽管我一直在远程关注。不过，谁知道呢？也许 X 平台上某个机器人已经悄然出现，开始在各种论战中大获全胜，或者一个用户发布的某种代码突然能生成令人难以置信的软件。你永远不知道，它可能不是一个盛大的发布，而是在某一天，一个机器人就开始赢得了所有的争论。

## 我的编程生涯：从约旦到硅谷

接下来，我想请您回顾一下个人经历，最初是如何接触到计算机的？

我在约旦安曼出生。在很小的时候，我就接触到了计算机。当时，我父亲只是一名政府工程师，收入并不丰厚，但他不知为何认为计算机很重要。他拿出积蓄买了一台电脑，那是我家乃至我们社区的第一台电脑，也是我所认识的人中拥有的第一台。我最早的记忆之一就是六岁时，看着父亲拆开这台机器，打开厚厚的说明书，笨拙地敲打着 `CD`、`LS`、`MKDIR` 等 DOS 命令。我常常在他身后，看着他输入这些命令，电脑也准确地响应并执行他的指令。

那是一台 IBM PC，大约在 1993 年。当时还没有 Windows 系统，或者说 Windows 是一个附加程序，需要从光盘启动。所以，很多时候我都在 DOS 环境下，编写批处理文件，打开游戏，折腾各种东西。直到 Windows 95 之后，我开始接触 Visual Basic，才真正开始编写软件。

### 第一次创业：网吧管理系统

我最早的一个想法源于我当时对游戏的热爱。我经常去网吧玩《反恐精英》（Counter-Strike）。我发现，虽然那里到处是电脑，但他们却没有使用任何软件来管理业务。工作人员只是跑来跑去，记录机器编号、你的使用时长以及支付金额，然后拍拍你的肩膀说：“嘿，你该多付点钱了。”我问他们为什么不开发一个软件，让玩家可以登录并计时。他们说不知道如何做到。我心想：“我大概知道怎么做。”

于是，在我大约 12 岁的时候，我花了两年时间构建了这个软件，并成功将其销售出去，赚到了不少钱。我记得麦当劳大约在我 13、14 岁时在约旦开业，我甚至请了全班同学去麦当劳大吃一顿，那可是相当昂贵的，但我当时赚得盆满钵满，也喜欢炫耀一下。这是我的第一个商业项目。

### 转向计算机工程与 Replit 的诞生

后来，我开始通过阅读科幻小说等方式了解人工智能。到了上大学的时候，我不想学习计算机科学，因为我觉得编码迟早会被自动化。我那时已经在使用一种叫“向导功能”的工具，它们是极其简陋的早期自动化工具，可以生成代码。你可以输入一些项目信息，然后点击几下，它就能生成大量基础代码。我当时觉得，“这就是未来，编程这事已经基本解决了。”既然 AI 可以写代码，那我该做什么呢？我决定去学习计算机工程，因为总要有人来构建和维护电脑。

然而，在计算机工程学习了一段时间后，我重新燃起了对编程的热爱，通过阅读关于 Lisp 等编程语言的文章，并开始尝试 Scheme 等语言。但我发现学习新的编程语言异常困难。当时我没有笔记本电脑，每次想学习 Python 或 Java，都必须去机房，下载几 GB 的软件，尝试安装配置，写几行代码，运行后却遇到缺少 DLL 文件之类的问题。我当时觉得：“天呐，这太原始了！”那大约是 2008 年左右，我们已经有了 Google Docs 和 Gmail，可以打开浏览器，像使用网络软件一样进行工作。我坚信网络才是终极的软件平台，所有软件都应该运行在网上。于是我开始思考：“谁在构建在线开发环境呢？”

然而，答案是“没有人”。这感觉就像我在大峡谷的地上捡到一张百元大钞般令人难以置信——如此显而易见的需求，竟然没有人做。所以，我决定自己尝试构建一个。

我花了几个小时就完成了一些东西：一个文本框，你可以输入 JavaScript 代码，点击一个名为“eval”的按钮，它就会执行代码并在弹窗中显示结果。例如，输入 `1+1`，结果是 `2`。我当时想：“我有一个编程环境了！”我给朋友们看，他们也开始使用。我又添加了一些功能，比如保存程序。我意识到这确实是个好主意，人们很喜欢。

然而，真正构建出有意义的东西又花了大约两到三年时间，因为浏览器当时只能运行 JavaScript。直到 Mozilla 的 Emscripten 研究项目出现，才带来了突破，它允许将 C、C++ 等编程语言编译成 JavaScript。为了让浏览器能运行 Python，我需要将 C 语言编写的 Python 解释器编译成 JavaScript。我成为了全球第一个做到这一点的人。我贡献了这个项目，并围绕其构建了大量辅助工具。我和朋友们成功将 Python 编译成 JavaScript。我们想：“既然 Python 成功了，那 Ruby、Lua 呢？”这就是 Replit 这一想法的萌芽。当你需要一个 REPL（Read-Eval-Print Loop，即交互式编程环境）时，你应该“Replit 它”。REPL 是最原始的编程环境。我陆续添加了这些编程语言，我的朋友们也一直在使用并为此兴奋不已。我当时习惯性地将所有软件开源，因此我也开源了这些能在浏览器中运行代码的底层基础设施。

然后，它就迅速走红了。



## 开放源码的病毒式传播与Codecademy

我耗费数年时间构建的底层基础设施，旨在实现在浏览器中运行代码。这个项目随后在Hacker News上爆红，恰逢大规模在线开放课程（MOOC）兴起的时代，Udacity、Coursera以及最著名的Codecademy等平台陆续上线。Codecademy是首批允许用户在浏览器中交互式编写代码并学习编程的网站之一，他们的许多功能都基于我在约旦开源的软件。

当我看到Codecademy在Hacker News上广为传播时，我立刻认出了自己开发的底层技术。我在评论区留言询问他们使用的技术，得知他们果然采用了我的开源软件包。随后，Codecademy联系了我，提出招聘意向。当时我并不感兴趣，因为我立志要创办自己的公司，也就是Replit。尽管他们一再劝说我加入，承诺可以共同实现相同的目标，但我仍坚持拒绝。最终，我同意以每小时12美元的合约形式为他们工作，当时身在阿曼的我对此感到非常兴奋。

Codecademy团队为了招募我，特地从约旦来到阿曼停留了几天。尽管我多次拒绝，但他们最终开出了一个我无法拒绝的条件，并帮助我获得了O1签证，使我得以移居美国。

### 移居美国的缘由

回溯到1987年我出生之后，最早萌生离开约旦、前往美国生活的念头，是在大约1998或1999年，观看电影《硅谷传奇》（Pirates of Silicon Valley）之后。这对我产生了深远影响。

### 校园经历与一次大胆尝试

在学校期间，我一直沉浸在编程中。我总是充满各种创业想法，渴望将它们付诸实践。Replit之所以存在，正是因为我随时都有新的想法，想立即在电脑上实现。因此，学校对我来说异常枯燥。Replit今天之所以有移动应用，也是因为我过去总想在课桌下偷偷编程。

由于经常缺课，尽管我的成绩都是A，但学校仍因为出勤问题让我挂科。这让我感到非常不公平。2011年左右，我的朋友们都陆续毕业了，而我却在大学里待了六年（原本应为三四年）。我感到非常沮丧，渴望前往硅谷。于是我心生一念：“如果我能修改自己的成绩呢？”

我开始着手入侵大学的数据库。我采取了达·芬奇所实践的多相睡眠法（polyphasic sleep）：每四小时小睡20分钟。这种方法与黑客工作模式不谋而合，因为许多安全漏洞的发现和脚本运行都需要耗时20-30分钟，我正好利用这段时间休息。我整整两周都在父母的地下室里疯狂尝试，最终找到了一处SQL注入漏洞。虽然我发现了编辑记录的方法，但不想冒险亲自动手。

我找到了一个同校的邻居，直接向他坦白：“我找到了一个可以修改成绩的方法，你愿意做我的‘小白鼠’吗？”他欣然同意。我们修改了他的成绩，但他打印出的成绩单上却没有更新。原来我只获得了“从属数据库”（slave database）的访问权限，而真正的“主数据库”（master database）仍未被攻破。

### 成功入侵与后果

我继续寻找，通过网络权限提升（privilege escalation）在Oracle数据库中发现了一个新的漏洞，最终访问到了真正的数据库。我修改了自己的成绩，并成功地在成绩单上看到了更新。我买了毕业礼服，参加了毕业派对，一切似乎都顺利结束了。

然而，一天傍晚，我接到了一个来自大学注册系统负责人的电话。他告诉我系统全天崩溃，问题反复指向我的记录。我的记录中存在一个异常：我既有及格成绩，又被禁止参加该科目的期末考试。这是因为数据库没有规范化，通常被禁止考试时，成绩会自动重置为35分，但我修改成绩时，没有注意到一个布尔标志位。大学数据库的所有列名都是单字母，这种“模糊安全”（security by obscurity）是最大的难点之一。

正是这个被我忽略的标志位，导致系统崩溃。我当时可以选择撒谎，但那将带来更大的麻烦，所以我决定坦白。我告诉他们第二天会去办公室解释。当我推开会议室的门时，看到所有学院的院长都在场，包括计算机科学学院的院长，他们连续多日都在研究这个系统问题。

### 面对校方与“蜘蛛侠”启示

所有人都对我的故事充满兴趣。我在白板上详细解释了我的入侵过程，像给他们上了一堂课，所有人都全神贯注。他们既感到惊奇，又觉得问题本身很有意思。会议结束时，他们不知如何处置我，是该送我入狱，还是？他们决定将此事上报给大学校长。

校长是一位非常开明的人，他给了我第二次机会。我向他解释了我的沮丧：我迫切需要毕业，开始新生活；我已经耗费六年时间在大学里，无法再忍受学习那些我早已掌握的知识。我自认是一名优秀的程序员。校长引用了“能力越大，责任越大”（with great power comes great responsibility）这句“蜘蛛侠”名言，这句话深深触动了我。

校长最终决定让我毕业，但条件是必须在暑假期间协助系统管理员加固系统安全。我欣然接受了。然而，当我报到时，所有程序员都对我怀恨在心，他们会故意将我锁在门外，不愿与我合作。我尝试提供帮助，但他们不予理睬。

### 毕业设计与新发现

临近毕业，到了提交最终项目的时候。一位计算机科学学院的院长找到我，说：“看，我需要你帮个忙。我们当初让你毕业而未起诉你，其中有我很大的功劳。我希望你和我一起完成最终项目，主题是安全和黑客。”我当时已经厌倦了黑客技术，只想专注于构建编程环境，但院长坚持要我做。

于是，我决定做一些更“有建设性”的事情。我编写了一个安全扫描器，它能够爬取网站，尝试进行SQL注入等各种攻击。令我自豪的是，我的安全扫描器竟然又在大学系统中发现了一个新的漏洞。在答辩时，院长要求我现场运行这个扫描器，展示这个新的漏洞。当时我并不完全理解他的用意，但我照做了。我完成了关于系统工作原理的演示，然后运行扫描器，它成功展示了系统中的安全漏洞。



## 现场演示与系统漏洞揭露

我演示了系统的工作原理，随后进行了一次现场运行。结果立即显示出系统存在安全漏洞，并成功获取了一个Shell。系统自动运行了所有安全检测程序，直接提供了一个Shell界面。

## 院长之怒与密码风波

此时，负责系统安全的一位院长脸色骤变，他正是下令确保系统安全的人。我突然意识到自己成了这场权力斗争中的一枚棋子。他气得满脸通红，断言系统是安全的，并指责我撒谎。我回应道：「你指控我撒谎，那么你想让我查什么？你的薪水，还是你的密码？」

他选择了密码。我查询了他的密码，一开始显示的是一串加密的乱码。他坚持说：「那不是我的密码，你在撒谎。」我指出：「程序员在系统里内置了一个解密功能。」我执行了「decrypt」操作，他的真实密码随即显示出来，那是一个令人尴尬的密码。他怒不可遏地站起身，与我握手后便匆匆离开，去修改密码。

## 毕业与未来路径的启示

幸运的是，我最终顺利毕业。我把开发的软件交给了学校，他们也借此机会修补了系统漏洞。后来我才明白，那位院长是想借此机会让另一位负责人难堪，而我只是他们权力斗争中的一枚棋子。

播客主持人评论道：「这故事的寓意是，如果你能成功入侵学校系统并修改你的成绩，那么你确实值得那个成绩，也值得毕业。」

他进一步阐述说：「我希望所有家长和孩子们都能以我为榜样，将其视为一种道德权威。对于人工智能时代来说，有一个非常重要的启示：循规蹈矩的传统道路带来的回报正越来越少。我认为，当今的孩子们应该充分利用所有可用的工具，去探索和开辟自己的道路。因为我觉得，仅仅听从传统建议，做前人一直在做的事情，已经不再像过去那样有效了。」
