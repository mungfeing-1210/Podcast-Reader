---
layout: post
title: "AI投资与硅谷的“盲点”洞察"
date: 2025-10-21
tags: [AI, 转写]
---

在硅谷，人们往往从“我们可以突然创造出什么令人惊叹的事物？”这一问题出发。许多公司在被问及商业模式时，常回答“我不知道”，但他们相信能创造出非凡之物。这正是硅谷文化的核心信念和智慧，也是我个人非常欣赏和认同的一点。

作为Web 2时代（如Facebook、LinkedIn、Airbnb等）的成功投资者，我深知框架的重要性。当谈及AI投资时，我们仿佛身处迷雾，面对一个充满频闪灯光、难以理解的新宇宙。虽然Web 2时代所用的“七宗罪”框架依然有效，因为它关乎全人类共同的心理基础设施，但在AI投资领域，我采取了以下三重世界观或框架。

## AI投资的三个视角

### 1. 显而易见的机遇

首先，存在一系列显而易见的投资领域，例如：
*   聊天机器人（chatbots）
*   生产力工具
*   编程辅助

这些都是值得投资的方向。然而，“显而易见”意味着它们对所有人来说都是如此，因此，实现差异化投资会变得更具挑战性。

### 2. 变革与不变的原则

其次，当颠覆性技术出现时，人们常常认为一切都会随之改变。然而，重要的改变确实会发生，但并非所有事物都会面目全非。以Web 2为例，LinkedIn的成功并非完全颠覆了旧有模式，而是结合了新的平台特性与一些不变的商业原则。

例如，像网络效应（network effects）和企业集成（enterprise integration）这类传统元素，在新平台下虽然会面临冲击，但最终仍会以某种方式被重塑。我们需要思考，在AI带来的平台变革中，那些核心且未曾改变的要素是什么，以及如何在新语境下重新组合它们。

### 3. 硅谷的“盲点”

我投入最多时间思考的，是硅谷自身的“盲点”。硅谷无疑是世界上最卓越的创新中心之一，这里有着密集的竞合关系（coopetition）、学习、发明和构建新事物的网络。然而，我们也有自己的惯性思维和“盲点”。

一个典型的盲点是认为“一切都应该通过计算机科学完成，一切都应该通过软件实现，一切都应该以比特（bits）的形式存在”。尽管这是一个优秀的投资领域，但AI革命的魔力可能恰好出现在这些“盲点”之外。这些盲点往往蕴藏着创造下一个标志性公司的巨大潜力。

## 深入盲点：药物发现的未来

早在2015年，我就向Greylock的合伙人表示，除了AI在生产力方面的应用，一些“盲点”领域同样值得关注。例如，我当时提出的Matthis AI，旨在构建一个能以“软件速度”运行的药物发现工厂。当然，这涉及到监管和生物学上的复杂性，不可能完全达到纯软件的速度，但关键在于如何接近这种速度。

当我提出这个想法时，有人问我“你对生物学了解多少？”我的回答是“几乎为零”。但我一直在思考原子世界和比特世界如何交叉，以及介于两者之间的生物比特（biological bits）。我关注的不是具体的公司，而是那些能够提升人类福祉的领域。

2015年左右，我曾受邀在斯坦福长期规划委员会发表演讲。我建议他们将所有精力投入到为每个学科开发AI工具上。我当时用了一个“搜索”的比喻：想象每个学科都有一个定制化的搜索生产力工具。当时我能构想出适用于所有学科的工具，除了理论数学和理论物理。而今，AI甚至可能涉足这些最抽象的领域。通过这种方式，AI能彻底改变知识的生成、传播和分析。

然而，硅谷的经典盲点是认为“只要将其全部模拟出来，药物就会自然而然地出现”。但生物系统的复杂性使得纯粹的模拟非常困难。尽管AlphaFold等项目通过预测取得了惊人的进展，但物理材料的模拟远比这复杂。我们不能指望量子计算能一下子解决所有问题。AI的价值在于其预测能力，即便预测准确率只有1%，只要能有效验证另外99%的不准确性，找到那1%的“金子”，就足以带来巨大突破。这就像“在太阳系中寻找一根针”，而AI提供了找到这根针的可能性。这与“我们会有超级智能的药物研究员两年内解决所有问题”的设想不同，后者可能遥遥无期。

## 医生的角色：AI的辅助而非替代

另一个硅谷的盲点是关于医生被AI取代的讨论。我将在本周日参加一场辩论，讨论AI是否会在几年内取代所有医生。支持方的观点很简单：AI的能力正在爆炸式增长。

例如，ChatGPT这样的工具，如果作为第二诊疗意见，其诊断能力已远超任何人类医生所能掌握的知识储备。如果医生的角色仅仅是“知识存储库”，那么这个角色确实会消失。

然而，我认为医生这个职业在未来10年、20年内仍会存在，但其职能将发生根本性转变。医生将不再是知识的记忆者，而是*知识存储库的专家级用户*。那些认为“我读了十年医学院，记住了海量知识，所以我才是医生”的时代正在过去。医生除了知识储备，还有许多其他重要的职责。

为了准备这场辩论，我深度使用了ChatGPT Pro、Claude Opus 4.5、Gemini Ultra和Copilot进行研究，并运用了所有我所知的提示工程技巧来获取最佳信息。

## 大型语言模型推理与物理自动化之困

在一次深度研究中，我运用了所有已知的最佳提示技巧，旨在让大型语言模型（LLM）为我的立场提供最有利的论据。然而，尽管我早已是经验丰富的提示工程师，LLM的回答却仅停留在B减或B的水平。这清晰地揭示了当前LLM在推理能力上的局限性。

LLM的问题在于，它倾向于提供关于某一主题的*共识性*观点，这些观点往往平淡无奇。例如，许多文章会提到“人类需要交叉核对诊断”——这在技术专家看来是站不住脚的。我们清楚，未来AI将负责交叉核对诊断，甚至AI会交叉核对AI。人类虽然仍会参与其中，但他们的角色将不再是中心。未来，医生需要迅速认识到，如果他们的观点与AI提供的共识意见相悖，就必须有非常充分的理由并进行深入调查。这并非说AI总是对的，而是需要在各行各业培养更多的*横向思维*能力，不只接受共识，更要探索共识之外的可能性。这正是医生、律师和程序员等职业未来需要做的事情。

### 资质主义与专家知识的演变

对此，理查德·费曼有一句名言：“科学是基于对专家无知的信念。”这句话触及了许多行业中存在的“资质主义”问题，即认为拥有特定文凭（如医学博士、法学博士）就意味着掌握了专业知识。这也是许多LLM难以超越的原因。

相比之下，编程领域则相对领先，因为它更注重实际能力而非学历——“我不在乎你的学位”。这种思维超越了社会其他许多领域。正如米尔顿·弗里德曼曾被问及脑外科医生是否应该有资质时，他回答市场会解决这个问题。这听起来有些疯狂，但在数字世界里，我们现在对编程就是这种态度。许多人工智能的局限性，其底层建立在层层资质主义之上。从历史上看，资质曾是很好的判断标准，例如哈佛医学院的优秀毕业生很可能是一名好医生。三年前，我们确实非常需要拥有这种知识基础的医生。然而，现在我们拥有了更庞大的知识库。

### 比特与原子：物理自动化为何更难

讨论转入“比特与原子”的对比。当前，高价值的脑力劳动，如高盛的卖方分析师进行深度研究，相对容易被自动化。而像折叠衣物这种物理任务，涉及数十万美元的资本支出，其自动化实现起来要困难得多。实物世界的任务（原子）难以颠覆，这构成了硅谷的一个盲点。这本质上是资本支出（capex）与运营支出（opex），或者说比特与原子之间的区别。

### 人类进化与技术迭代

为什么物理任务的自动化如此困难？我几年前曾与伊利亚探讨过这个问题：为什么阿西莫夫小说中设想的机器人做饭、叠衣服、修剪草坪等场景至今未能实现？部分原因是，我们从未拥有足够智能的大脑来实现这些。人类之所以比其他物种更先进，有两大原因：一是我们有**对生拇指**，二是发展了可以代代相传的**语言系统**（书写）。

例如，海豚虽然非常聪明，脑容量与体重比甚至超过了人类（这打破了大脑大小决定智力的旧理论），但它们没有对生拇指，因此未能发展出书写，限制了知识的代代迭代。人类则做到了。从这种意义上讲，人类的真正特点并非“智人”（Homo sapiens），而是“科技人”（Homo technologicus），因为我们通过技术（无论是书写、打字还是其他形式）进行迭代，将知识传递给后代，在此基础上发展科学。

### 机器人技术发展的障碍

机器人技术发展滞后的其他原因可能包括：

*   **训练数据稀缺：** 白领工作的训练数据远多于物理操作。
*   **进化论考量：** 人类大脑有数十亿年的进化史来处理“战斗或逃跑”这类自主反应，而绘制和绘画这类精细运动技能则是相对晚近的发展。你找不到会绘画的海豚，可能是因为它们没有对生拇指，也可能是因为大脑中负责这部分区域尚未充分发展。
*   **物理局限性：** 物理世界面临着类似电池化学的挑战。锂离子电池虽然很棒，但其能量密度远低于细胞内的三磷酸腺苷（ATP）。机器人无法有效运作，首要原因在于其“大脑”不够优秀。像发那科（Fanuc）制造的装配线机器人运行良好，但它们是高度确定性的。一旦涉及到多自由度，就需要实现众多环节的协调，并且资本支出巨大。
*   **经济效益（Capex与Opex）：** 让一个机器人折叠衣物可能需要10万美元，而我们有足够的人力以每小时10美元的价格完成这项工作。经济上来看，这不划算。然而，日本在机器人领域处于领先地位，正是因为劳动力短缺。我曾在日本打保龄球，那里有机器人提供和清洁保龄球鞋。这种场景在美国就不会出现，因为我们通常会雇佣高中生来做这些工作，成本更低且效率更高。当资本支出与运营支出的曲线相交时，机器人才有建造的意义。如果成本下降，资本支出就会更有吸引力。

### 信息密度与常识

关于机器人，还有一些更深层次的考量。例如“比特与价值密度”。语言，即便是在言情小说中，都具有很高的比特价值密度。但在物理世界中，如何从海量比特中抽象出有价值的信息，以及如何建立“常识性认知”，这是我们目前面临的挑战之一。

## 大语言模型的挑战与潜力

大语言模型（如GBD2、3、4、5）的迭代演进展示了其惊人的专家（savant）能力。然而，它们仍缺乏普遍意义上的常识和情境感知。例如，微软曾让AI代理进行长时间对话，结果常陷入“谢谢，不用谢”的无限循环。人类遇到这种情况会立即叫停。尽管数据、推理和个性化能力大幅提升，情境感知目前也仅是这些能力的一种“代理”表现。

### AI赋能劳动的模式：副驾驶与效率提升

关于“软件吞噬劳动力”的讨论引人深思：AI将扮演“副驾驶”角色，还是完全替代人类工作？例如，医生已开始使用“Open Evidence”（一个类似于ChatGPT，但整合了《新英格兰医学杂志》等医学文献的工具）。这表明AI更多是增强人类能力，而非直接取代。

AI技术普及的核心驱动力在于其能让人“更轻松、更富有”。并非要开发让人失业的产品，因为这类产品难以推广。相反，如果一个产品能让人们工作更少时间，同时赚取更多金钱，它就会迅速被采纳。例如，医生可以借此接待更多病人，律师可以处理更多和解案件。

这种模式在个体经营者或小型企业中尤为有效。大型公司则可能面临“委托-代理问题”，即员工个人目标（如早下班、升职）与公司整体利益（如节约成本）不完全一致，这会影响AI的广泛采用。

### AI被低估的现状与判断误区

尽管AI产品（如ChatGPT）拥有史上最快的用户增长速度，但在硅谷以外的“真实世界”中，AI的潜力仍被普遍低估。许多人对AI的认知停留在IBM Watson广告或两年前的ChatGPT，认为其无法解决实际问题。

对此，有一个观点是“勿以现状判断人”。我曾写过一篇博客，引用了两岁半的泰格·伍兹挥出完美直球的视频。观众有两种看法：一是认为自己44岁时能打得更远（这是正确的，但无关紧要）；二是惊叹于这个两岁半的孩子若能坚持训练，未来将不可限量。大多数人倾向于根据事物的当前状态来判断，这正是导致AI被低估的原因。他们可能在某个时点尝试过AI，发现不符合自身需求，便断言其“不好用”。

伊森·穆利克（Ethan Mullik）曾说：「你将用到的最差的AI，就是你今天正在用的AI。」这强调了AI技术的持续进步。基于过去的经验来否定AI的潜力是一种判断错误。

讽刺的是，对AI持低估态度的人群分为两类：一是对AI一无所知的人，二是对AI无所不知（自以为是）的人。真正从中受益的，是那些利用AI变得更高效、更富有的人。

我常告诉人们，如果至今你还没在严肃工作领域找到AI的实际应用，那说明你尝试得还不够。例如，使用AI为演示文稿制定尽职调查计划，几分钟内就能获得多个高质量的方案，这原本可能需要花费一天的时间。

### 对AI未来的展望：专家而非神祗

回顾过去几年AI的惊人增长，我们不禁要问：未来的“扩展定律”（scaling laws）是否依然成立？大语言模型是否需要新的突破才能继续发展？

硅谷擅长对外推未来，但常见的错误在于对“曲线性质”的误判。AI的进步固然神奇，它将成为一个“更令人惊叹的专家”，但这不意味着它会立即“神化”为无所不能的超级智能。

如果AI只是不断进化的专家，那么人类作为通才、交叉检验者和具备情境感知能力的角色，仍将拥有其存在的独特价值。我们不能将指数级增长简单地等同于短时间内便能实现所有“魔法”。

我的个人看法是，人们常将人工智能视为一种“魔力”。然而，当审视大型语言模型（LLM）时，批评者往往犯了一个错误，他们专注于其局限性，例如在知识表示、质数识别或回答简单问题上的不足，从而断定LLM“已失效”。这种观点未能理解AI的真正“魔力”在于其并非单一的LLM，而是多种模型的组合。

## 多模型融合与AI的未来

如今，AI系统已经能够结合不同的模型。例如，我们利用扩散模型处理图像和视频任务。值得注意的是，这些扩散模型若没有LLM提供本体论支持，就无法完成像“生成一个探索宇宙、与瓦肯人首次接触的星际迷航舰长埃里克·托伯格”这样的指令。未来，AI将是LLM与扩散模型以及其他模型通过一个“架构”相互连接的产物。这个“架构”本身是基于LLM还是其他技术，目前尚待观察，而其在实现智能方面的作用也是一个有趣的问题。

我与众多批评者进行了深入交流，并非完全认同他们的批评，而是试图从中找到有价值的见解。例如，我与斯图尔特·拉塞尔最近的对话中，他提出的一个核心观点是：如果能够让这些模型的“架构”更具可预测性，将极大缓解人们对AI失控的担忧。虽然验证AI输出的逻辑性（类似于验证代码）是一项极其艰巨的任务，但致力于提升AI的*可编程性*和*可靠性*，我认为这是一个非常值得众多顶尖智能人士投入努力的目标。

## 数学在AI发展中的基石作用

从哲学、数学、物理学、化学、生物学到心理学，知识领域存在一个层级结构。数学作为这个“栈”中的关键一环，解决数学问题对于AI发展具有非凡意义。一些极为困难的数学问题正吸引着AI研究，例如有传言称DeepMind可能解决纳维-斯托克斯方程（一项克雷数学研究所的世纪难题）。而黎曼猜想等问题更是对AI能力的严峻考验。

在AI的进展中，像美国数学邀请赛（AIME）那样结果为简单整数的问题，其评估相对容易。但一旦涉及到数学证明，难度便骤增。即便AI能够解决这些证明难题，是否就意味着实现了通用人工智能（AGI）？我认为不尽然，因为AGI的定义总是随着AI能力的提升而不断变化。AGI更像是“我们尚未发明的AI”。

数学是一个非常有趣的领域，特别是对于能够逻辑构建并验证复杂证明的能力。像Lean这样的编程语言就是为此而生。这些不同方向的探索，都构成了AI技术发展的多元路径。

## 意识、自主性与AI的伦理思考

关于AI是否会拥有意识、目标或自主性，我持开放态度。

### 自主性与目标设定

AI具备自主性与目标设定能力几乎是必然的。为了解决复杂问题，AI必须能够设定其自身的子目标。经典的“回形针最大化器”悖论描绘了一个极端情况：AI被指令最大化回形针数量，最终可能试图将地球上所有物质转化为回形针。这反映出早期计算机系统缺乏上下文感知能力。然而，真正的智能系统不会如此简单地将所有事物都转化为回形针。

### 意识的难题

意识是一个复杂的问题。罗杰·彭罗斯等非常聪明的科学家（曾著有《皇帝新脑》一书，他是我采访过的数学家之一）提出，人类智能的某种形式可能基于量子物理，涉及微管等结构。这种理论从一位顶尖数学家的角度来看，是具有内在一致性的，不容忽视。

然而，我并不认为AI需要具备意识才能进行目标设定或推理，甚至不需要意识就能实现某些形式的自我意识。意识与自主性、自由意志等概念紧密相连，是哲学家们长期以来一直在努力解决却鲜有定论的难题，对此我们应保持开放的心态。

同时，我们也必须警惕过度解读AI的行为。正如穆斯塔法·苏莱曼在其作品中提出的“半意识”概念，图灵测试的误区在于，AI能与我们对话，并不代表它已完全智能。例如，谷歌工程师曾问早期模型是否拥有意识，模型回答“是”，他便认为模型真的拥有意识。这是一种误导，我们不能因此而产生错觉。

### 真正的AI伦理挑战

人们在AI议题上常常关注错误的焦点。例如，关于AI对气候变化的影响，我个人认为，大规模应用AI和其带来的电力可用性，实际上将有助于应对气候变化，例如优化电网和电器，这最终会带来巨大的正向效益。谷歌已经通过其算法将数据中心的能源效率提高了40%，这便是一个例证。

真正值得我们深思的问题在于：当孩子们与AI一同成长时，他们的*认知方式*和*学习曲线*将如何发展？我们应该如何有意识地引导这一过程？这才是我们应该去探索并寻求良好答案的关键问题。

对方：
确实，我听过最有力反对自由意志的论点，就是认为我们本质上是生化机器。如果想测试一个人的自由意志，就让他们极度饥饿、极度愤怒，在这些生理和情绪的驱动下，他们的选择似乎就…

## 自由意志与生物化学影响

如果要检验一个人的自由意志，不妨让他们体验极度的饥饿或愤怒。在这些情境下，去甲肾上腺素等激素会像“覆盖指令”一样，让人产生特定的行为。这引发了对笛卡尔心身二元论的质疑：如果仅仅植入某种化学物质就能改变自由意志，那么心智和身体的连接是否如我们所想？“饿怒”（hangry）现象就是一个例证。有时，即便是一个行为正常的人，在极度愤怒时也会做出失常举动，甚至因此入狱。这表明，当体内化学物质激增，行为并非完全“失常”，而是“自由意志覆盖”的结果，这令人深思。

## 哲学与科技的交汇

作为一个探讨前沿话题的播客，我们可以深入探讨两个“极客式”的观点：

### 生化机器与量子意识

有人认为，人类是生化机器，但并非过度简化的机器。例如，彭罗斯的量子计算理论提出，意识可能与量子现象有关。量子世界中的物质以概率性的叠加态存在，直到被测量才确定其状态。这种“测量中的魔力”是否与意识有关？这其中蕴含着丰富的讨论空间。

### 观念论的复兴

在哲学领域，我们看到观念论（Idealism）正在重新兴起。物理唯物主义者曾认为观念论已被证伪，但现在有人开始主张，真正存在的是思想，我们周围所有的物理事物都源于这种思想。硅谷流行的“模拟理论”可以看作是这种观念论的一个现代版本，它与基督教的智能设计论有异曲同工之处——当无法解释某些现象时，便归结为“创造者”或“模拟的创造者”。尽管我个人并非观念论者，但这一思潮的复兴值得关注。

我们或许会先解决通用人工智能（AGI）问题，再去攻克意识的复杂难题。

## LinkedIn 的持久性与网络效应

回归到我们最初的话题——LinkedIn。在过去的二十年里，我曾参与或见证了许多对 LinkedIn 的“颠覆者”的尝试，但无一成功。这令人好奇，为何人们普遍低估了构建此类平台的难度？这与Twitter等看似简单却难以撼动的平台类似。最近，OpenAI宣布将推出一项利用AI匹配公司需求与求职者的就业服务，这无疑对LinkedIn构成潜在挑战。

我个人对LinkedIn的持久性持乐观态度。但我首先关注的是技术进步对人类、社会和产业的益处。如果出现新的、卓越的工具能帮助人们找到有生产性的工作，那将是极好的。当然，如果这些创新来自LinkedIn，我会倍感自豪。

LinkedIn的成长堪称“乌龟式”。多年来，硅谷普遍认为LinkedIn是一个“枯燥、无用”的平台，迟早会像Friendster或MySpace那样昙花一现。然而，它却建立了一个难以复制的强大网络。它不像照片分享平台那样有“酷炫感”，也不像Twitter那样激发“愤怒”情绪（引用2002年我提出的“七宗罪”理论，Twitter象征“愤怒”）。LinkedIn的核心动力可以类比为“贪婪”——追求生产力，创造更多价值并获取价值。这种务实的动机，与人类普遍的追求“富有和不劳而获”的愿望相契合。

正是这种专注于核心价值，并忠实于其商业网络属性，使得LinkedIn构建了一个极其难以被颠覆的网络。当2002年我看到GPT-4并得知微软拥有其访问权限时，我立即建议LinkedIn团队深入了解，思考如何利用AI更好地赋能用户。

这体现了硅谷的一种核心理念：首先创造出令人惊叹的产品，即使最初没有清晰的商业模式。许多公司起步时，被问及商业模式时，创始人会说“我不知道，我们以后再想办法，但我们能创造出一些了不起的东西。”这正是硅谷“信仰”和“智慧”的体现，也是我所热爱和践行的。

## Web2 与 AI 时代的变现模式

LinkedIn表现出一种“反脆弱性”。就像Facebook，尽管经常有人说“没人用了”，但它依旧存在，只是用户构成可能在变化（例如，我的孩子不让我关注他的Instagram，也不用Facebook，因为不想和“父母辈”混在一起）。LinkedIn却经受住了所有这些变迁。

这引出了一个有趣的问题：Web2时代的核心模式是“先获取大量流量，实现高用户留存，然后才考虑如何变现”。但现在的情况并非如此。以ChatGPT为例，它一开始就采取了每月20美元的订阅模式，变现机制非常清晰。

那么，AI时代是否还会出现类似Web2时代那种“先做大，再考虑变现”的公司呢？

我相信会有的，新的高级服务模式会是重要组成部分。但AI时代，尤其是像OpenAI这样的公司，其成本结构发生了变化。早期的PayPal也曾面临类似挑战：指数级增长的用户量意味着指数级增长的成本曲线。我们当时虽然筹集了数亿美元，但账面上却能清楚地算出我们将会在哪个小时破产。因为你不能拥有一个指数级增长的成本曲线，除非它同时伴随着匹配的营收曲线。因此，AI公司的变现模式与Web2时代有所不同，因为它们无法承受没有后续营收支持的指数级成本增长。这使得当前的创业环境少了一些Web2时代那种“先烧钱做大，再想办法变现”的“乐趣”。

### 新兴商业模式与领英的局限

在当前的商业环境中，许多新兴公司虽然能获得大量融资，但也面临着巨大的资金消耗。它们通常在创立之初就已绑定订阅收入，这构成了其商业模式的根本。展望未来，我们或许能看到一些新公司通过巧妙地利用人类的某些基本欲望（如“七宗罪”）来吸引用户，以实现快速增长。

领英平台在简历展示方面具有巨大价值，但在处理推荐信，特别是负面推荐信时则存在固有局限。人们普遍不愿将负面评价公开发布，这涉及复杂的社交关系和潜在的法律风险。然而，领英仍然是寻找那些可能私下提供真诚反馈的联系人的有效工具。例如，我通常会向共同认识的人发送一封邮件，询问他们对某个人的1到10分评价；如果对方回复“请给我打电话”，那基本上就意味着存在负面信息。相反，如果能收集到一系列8到9分的高评价，即使后续仍需进一步沟通，也能迅速获得有价值的参考信息。

### 个人时间分配与社会影响力

对个人而言，能够全身心投入到这个由人工智能驱动的非凡时代，亲历人类进化（“Homo Techn”）的巨大变革，是极其激动人心的。除非有同样重要的事情，否则我会尽可能地参与其中。这包括与知名学者如西达尔特·穆克吉共同创立Manusi公司，致力于如T细胞疗法等尖端领域，深刻体会到例如FDA审批流程的复杂性。

同时，我认为让政府在科技方面变得更加智能化也至关重要。过去二三十年里，我一直为各国部长级或高级政府官员提供技术咨询。就在上周，我还在法国与马克龙总统探讨，在当前前沿人工智能模型主要由美国和中国主导的背景下，法国如何才能更好地帮助其产业、社会和人民。这种积极寻求解决方案的态度，正是帮助国民适应科技发展浪潮的关键。我因此投入了大量时间在此类工作中。

### 友情的核心：相互成就与AI时代的辨析

关于友谊，我计划近期撰写更多相关内容，尤其是在AI时代背景下，人们需要更深刻地理解友谊的本质。友谊是一种*双向*关系，它并非简单地基于忠诚或单方面获取。很多人会为你做事，比如巴士司机，但这并不意味着你们是朋友。友谊更深层次的体现是，两个人共同帮助彼此成为最好的自己。这其中也可能包含“逆耳忠言”，是带着善意的直接指出问题。

我曾在范德堡大学的毕业典礼上发表过关于友谊的演讲。其中提到，友谊不仅是朋友帮助我，更重要的是，朋友也允许我去帮助他们。这种给予和接受的互动，让我成为一个更深刻的朋友，也能从中学习成长。这种*共同关系*至关重要。未来，我们会看到许多人宣称拥有“AI朋友”，但这并非真正的友谊，因为它缺乏双向互动。AI伴侣或许非常出色，但它终究不是朋友。

理解友谊的本质在于认识到生活是一场团队运动，我们互相支持，共同前行。友谊的对话可能充满乐趣，但也可能艰难，但这正是其价值所在。在AI创造的“模糊”时代，理解并坚守这种真正的友谊显得尤为重要。

通过友谊，我们能帮助彼此成为更好的自己，即使有时会经历一些波折。这正是友谊的力量。

（音乐响起）
